{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.12.0"
      ],
      "metadata": {
        "id": "s8bKdL-1gpsJ",
        "outputId": "4e26b03d-7ced-4e25-de10-7a0da476b14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.74.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.14.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.5.2)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12.0)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.14.1)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.7.0,>=0.7.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.7.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading ml_dtypes-0.5.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.2,>=0.6.2 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.1,>=0.6.1 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.16.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.7.14)\n",
            "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scipy>=1.9 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading scipy-1.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.1)\n",
            "Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, gast, scipy, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.20 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "geopandas 1.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.90 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "contourpy 1.3.3 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 2.12.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 protobuf-4.25.8 scipy-1.15.3 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "google",
                  "jax",
                  "jaxlib",
                  "keras",
                  "numpy",
                  "scipy",
                  "tensorflow",
                  "wrapt"
                ]
              },
              "id": "28427bbc5f454e5eafcc8f4465d874bb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "haT97EGZgiB2",
        "outputId": "c3b17b2d-ecba-47de-e159-f82971c4d9de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "position=tf.range(5, dtype=tf.float32)\n",
        "print(position)\n",
        "position = position[:, tf.newaxis]  # position.reshape(-1, 1)\n",
        "print(position)"
      ],
      "metadata": {
        "id": "AaiUpX1Eh30g",
        "outputId": "9e7601aa-1809-4ba7-9de2-5bdb59eb26df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0. 1. 2. 3. 4.], shape=(5,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.]\n",
            " [1.]\n",
            " [2.]\n",
            " [3.]\n",
            " [4.]], shape=(5, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=tf.range(10, dtype=tf.float32)\n",
        "print(i)\n",
        "i = i[tf.newaxis, :]  # i.reshape(1,-1)\n",
        "print(i)"
      ],
      "metadata": {
        "id": "M2Rei_WTighv",
        "outputId": "b91f5e8a-26f2-40b9-98f4-7da337ee0851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], shape=(10,), dtype=float32)\n",
            "tf.Tensor([[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]], shape=(1, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = position * i  # (5,1)*(1,10) => (5,10)*(5,10)\n",
        "print(out.shape)\n",
        "print(out)"
      ],
      "metadata": {
        "id": "umaxZnC_i9_k",
        "outputId": "c0bb6661-b9b3-4944-dc7b-972e48592ea7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 10)\n",
            "tf.Tensor(\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
            " [ 0.  2.  4.  6.  8. 10. 12. 14. 16. 18.]\n",
            " [ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n",
            " [ 0.  4.  8. 12. 16. 20. 24. 28. 32. 36.]], shape=(5, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(10, tf.float32))\n",
        "print(angles)"
      ],
      "metadata": {
        "id": "R0iqzw4akOvw",
        "outputId": "c396aee1-9cf1-49ea-82fc-d535fe35bf7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1.0000000e+00 1.0000000e+00 1.5848932e-01 1.5848932e-01 2.5118863e-02\n",
            "  2.5118863e-02 3.9810706e-03 3.9810706e-03 6.3095731e-04 6.3095731e-04]], shape=(1, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = position * angles  # (5,1)*(1,10) => (5,10)*(5,10)\n",
        "print(out.shape)\n",
        "print(out)"
      ],
      "metadata": {
        "id": "Wz1lklIXkauf",
        "outputId": "e251db86-2c63-45bc-e97f-0763c6a8f7e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 10)\n",
            "tf.Tensor(\n",
            "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [1.0000000e+00 1.0000000e+00 1.5848932e-01 1.5848932e-01 2.5118863e-02\n",
            "  2.5118863e-02 3.9810706e-03 3.9810706e-03 6.3095731e-04 6.3095731e-04]\n",
            " [2.0000000e+00 2.0000000e+00 3.1697863e-01 3.1697863e-01 5.0237726e-02\n",
            "  5.0237726e-02 7.9621412e-03 7.9621412e-03 1.2619146e-03 1.2619146e-03]\n",
            " [3.0000000e+00 3.0000000e+00 4.7546795e-01 4.7546795e-01 7.5356588e-02\n",
            "  7.5356588e-02 1.1943212e-02 1.1943212e-02 1.8928719e-03 1.8928719e-03]\n",
            " [4.0000000e+00 4.0000000e+00 6.3395727e-01 6.3395727e-01 1.0047545e-01\n",
            "  1.0047545e-01 1.5924282e-02 1.5924282e-02 2.5238292e-03 2.5238292e-03]], shape=(5, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.sin((90.*3.1415926535897932384626433832795)/180.)"
      ],
      "metadata": {
        "id": "FcAZDZrZkjzJ",
        "outputId": "6fb63092-c02a-45fd-de5e-5386cc1a09c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.math.sin(1.)\n",
        "# tf.math.sin(0.15848932)"
      ],
      "metadata": {
        "id": "dyV7DdgplSn1",
        "outputId": "5677f2cb-bc4d-4276-da04-a9a372604780",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.15782663>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yxLs2EGPcOUS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, position, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "        return position * angles\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "            d_model=d_model)\n",
        "\n",
        "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "\n",
        "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "        # print(pos_encoding.shape)\n",
        "        return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kA6-IyNtcOUT",
        "outputId": "48042d06-5bba-460c-9355-0f37fe886db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 50, 128)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sample_pos_encoding = PositionalEncoding(50, 128)\n",
        "\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqWMq3incOUU"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
        "\n",
        "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
        "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "#     print(\"matmul_qk=\", matmul_qk)\n",
        "    # 스케일링\n",
        "    # dk의 루트값으로 나눠준다.\n",
        "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "#     print(\"depth=\",depth)\n",
        "    logits = matmul_qk / tf.math.sqrt(depth)\n",
        "#     print(\"logits=\",logits)\n",
        "\n",
        "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
        "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "\n",
        "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
        "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
        "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "#     print(\"attention_weights=\",attention_weights)\n",
        "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "\n",
        "    return output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6rKhmYycOUV"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "temp_k = tf.constant([[10,0,0],\n",
        "                      [0,10,0],\n",
        "                      [0,0,10],\n",
        "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
        "\n",
        "temp_v = tf.constant([[   1,0],\n",
        "                      [  10,0],\n",
        "                      [ 100,5],\n",
        "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
        "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRvn5WxacOUW"
      },
      "outputs": [],
      "source": [
        "# temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
        "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
        "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
        "print(temp_out) # 어텐션 값"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-tJpJW7cOUW"
      },
      "outputs": [],
      "source": [
        "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
        "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
        "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
        "print(temp_out) # 어텐션 값"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77yGyUepcOUX"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "        super(MultiHeadAttention, self).__init__(name=name)\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        # d_model을 num_heads로 나눈 값.\n",
        "        # 논문 기준 : 64\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
        "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "        # WO에 해당하는 밀집층 정의\n",
        "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        inputs = tf.reshape(\n",
        "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "            'value'], inputs['mask']\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
        "        # q : (batch_size, query의 문장 길이, d_model)\n",
        "        # k : (batch_size, key의 문장 길이, d_model)\n",
        "        # v : (batch_size, value의 문장 길이, d_model)\n",
        "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "\n",
        "        # 2. 헤드 나누기\n",
        "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
        "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
        "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # 4. 헤드 연결(concatenate)하기\n",
        "        # (batch_size, query의 문장 길이, d_model)\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "        # 5. WO에 해당하는 밀집층 지나기\n",
        "        # (batch_size, query의 문장 길이, d_model)\n",
        "        outputs = self.dense(concat_attention)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBC1-nshcOUX"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(x):\n",
        "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "    # (batch_size, 1, 1, key의 문장 길이)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy7xxC2EcOUY"
      },
      "outputs": [],
      "source": [
        "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtykutRJcOUZ"
      },
      "outputs": [],
      "source": [
        "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "    # 인코더는 패딩 마스크 사용\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
        "    attention = MultiHeadAttention(\n",
        "        d_model, num_heads, name=\"attention\")({\n",
        "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "            'mask': padding_mask # 패딩 마스크 사용\n",
        "        })\n",
        "\n",
        "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "    attention = tf.keras.layers.LayerNormalization(\n",
        "        epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
        "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "        epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRiJI0kDcOUZ"
      },
      "outputs": [],
      "source": [
        "def encoder(vocab_size, num_layers, dff,\n",
        "            d_model, num_heads, dropout,\n",
        "            name=\"encoder\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "    # 인코더는 패딩 마스크 사용\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    # 포지셔널 인코딩 + 드롭아웃\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    # 인코더를 num_layers개 쌓기\n",
        "    for i in range(num_layers):\n",
        "      outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "          dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
        "      )([outputs, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpKU8zzDcOUa"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(x):\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
        "    return tf.maximum(look_ahead_mask, padding_mask)\n",
        "#     return look_ahead_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdzLKeJecOUa"
      },
      "outputs": [],
      "source": [
        "print(create_look_ahead_mask(tf.constant([[4, 0, 0, 2, 5]])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5tiEtIycOUa"
      },
      "outputs": [],
      "source": [
        "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "\n",
        "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
        "    attention1 = MultiHeadAttention(\n",
        "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "            'mask': look_ahead_mask # 룩어헤드 마스크\n",
        "        })\n",
        "\n",
        "    # 잔차 연결과 층 정규화\n",
        "    attention1 = tf.keras.layers.LayerNormalization(\n",
        "        epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
        "    attention2 = MultiHeadAttention(\n",
        "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "            'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
        "            'mask': padding_mask # 패딩 마스크\n",
        "        })\n",
        "\n",
        "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "    attention2 = tf.keras.layers.LayerNormalization(\n",
        "        epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
        "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "        epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "        outputs=outputs,\n",
        "        name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt4dIRywcOUb"
      },
      "outputs": [],
      "source": [
        "def decoder(vocab_size, num_layers, dff,\n",
        "            d_model, num_heads, dropout,\n",
        "            name='decoder'):\n",
        "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "\n",
        "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "        shape=(1, None, None), name='look_ahead_mask')\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    # 포지셔널 인코딩 + 드롭아웃\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    # 디코더를 num_layers개 쌓기\n",
        "    for i in range(num_layers):\n",
        "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
        "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "        outputs=outputs,\n",
        "        name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffz-Myu7cOUb"
      },
      "outputs": [],
      "source": [
        "def transformer(vocab_size, num_layers, dff,\n",
        "                  d_model, num_heads, dropout,\n",
        "                  name=\"transformer\"):\n",
        "\n",
        "    # 인코더의 입력\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "    # 디코더의 입력\n",
        "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "    # 인코더의 패딩 마스크\n",
        "    enc_padding_mask = tf.keras.layers.Lambda(\n",
        "        create_padding_mask, output_shape=(1, 1, None),\n",
        "        name='enc_padding_mask')(inputs)\n",
        "\n",
        "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
        "    look_ahead_mask = tf.keras.layers.Lambda(\n",
        "        create_look_ahead_mask, output_shape=(1, None, None),\n",
        "        name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "    # 디코더의 패딩 마스크(두번째 서브층)\n",
        "    dec_padding_mask = tf.keras.layers.Lambda(\n",
        "        create_padding_mask, output_shape=(1, 1, None),\n",
        "        name='dec_padding_mask')(inputs)\n",
        "\n",
        "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
        "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
        "\n",
        "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
        "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "    # 다음 단어 예측을 위한 출력층\n",
        "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLxWScf0cOUb"
      },
      "outputs": [],
      "source": [
        "small_transformer = transformer(\n",
        "    vocab_size = 9000,\n",
        "    num_layers = 4,\n",
        "    dff = 512,\n",
        "    d_model = 128,\n",
        "    num_heads = 4,\n",
        "    dropout = 0.3,\n",
        "    name=\"small_transformer\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJNVw_1TcOUb"
      },
      "outputs": [],
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "    loss = tf.multiply(loss, mask)\n",
        "\n",
        "    return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "rJ1vNpGXcOUc"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")\n",
        "# Text(0.5, 0, 'Train Step')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45Pau5Z2cOUc"
      },
      "source": [
        "#### tensorflow_datasets 처음 설치 시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsEC3OYscOUc"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sETL7LzLcOUd"
      },
      "source": [
        "#### tensorflow_datasets 업그레이드 시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVMre0s3cOUd"
      },
      "outputs": [],
      "source": [
        "!pip3 install --user --upgrade tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmYGIpIScOUd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "import time\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHM8r2mrcOUd"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLWI_CwdcOUd"
      },
      "outputs": [],
      "source": [
        "print(tfds.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsY175pNcOUd"
      },
      "outputs": [],
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\", filename=\"ChatBotData.csv\")\n",
        "train_data = pd.read_csv('ChatBotData.csv')\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dApmECCWcOUe"
      },
      "outputs": [],
      "source": [
        "print('챗봇 샘플의 개수 :', len(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpgdVc-7cOUe"
      },
      "outputs": [],
      "source": [
        "print(train_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGIKXXATcOUe"
      },
      "outputs": [],
      "source": [
        "questions = []\n",
        "for sentence in train_data['Q']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    questions.append(sentence)\n",
        "answers = []\n",
        "for sentence in train_data['A']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    answers.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPfTgcGpcOUe"
      },
      "outputs": [],
      "source": [
        "print(questions[:5])\n",
        "print(answers[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIqLNEsUcOUf"
      },
      "outputs": [],
      "source": [
        "# 서브워드텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size=2**13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVOjQhgScOUf"
      },
      "outputs": [],
      "source": [
        "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCX8A-TkcOUf"
      },
      "outputs": [],
      "source": [
        "print('시작 토큰 번호 :',START_TOKEN)\n",
        "print('종료 토큰 번호 :',END_TOKEN)\n",
        "print('단어 집합의 크기 :',VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt_w-F7kcOUf"
      },
      "outputs": [],
      "source": [
        "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
        "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEQoTF0_cOUf"
      },
      "outputs": [],
      "source": [
        "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
        "# 임의의 입력 문장을 sample_string에 저장\n",
        "sample_string = questions[20]\n",
        "\n",
        "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print ('기존 문장: {}'.format(original_string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BURqD4H4cOUg"
      },
      "outputs": [],
      "source": [
        "for ts in tokenized_string:\n",
        "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_XgotRgcOUg"
      },
      "outputs": [],
      "source": [
        "# 최대 길이를 40으로 정의\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    tokenized_inputs.append(sentence1)\n",
        "    tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "questions, answers = tokenize_and_filter(questions, answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAmtMnNicOUg"
      },
      "outputs": [],
      "source": [
        "print('질문 데이터의 크기(shape) :', questions.shape)\n",
        "print('답변 데이터의 크기(shape) :', answers.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF0E7MJccOUl"
      },
      "outputs": [],
      "source": [
        "print(questions[0])\n",
        "print(answers[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXsD2yxxcOUl"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
        "print(answers[0]) # 기존 샘플\n",
        "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
        "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zN-VNmHEcOUl"
      },
      "outputs": [],
      "source": [
        "D_MODEL = 256\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 8\n",
        "DFF = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dff=DFF,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpvXqPjycOUm"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-a61P0xcOUm"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xOlI-WIcOUm"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 예측 시작\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
        "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence\n",
        "def preprocess_sentence(sentence):\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PACHCuMLcOUm"
      },
      "outputs": [],
      "source": [
        "output = predict(\"날씨가 좋넹.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYASEa8ocOUm"
      },
      "outputs": [],
      "source": [
        "output = predict(\"고민이 있어\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBHTq6GJcOUm"
      },
      "outputs": [],
      "source": [
        "output = predict(\"너무 화가나\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxT8GlVtcOUn"
      },
      "outputs": [],
      "source": [
        "output = predict(\"카페갈래?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx0Cls29cOUn"
      },
      "outputs": [],
      "source": [
        "output = predict(\"게임하고싶당\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vCPxvQucOUn"
      },
      "outputs": [],
      "source": [
        "output = predict(\"게임하자\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvLAro04cOUn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}